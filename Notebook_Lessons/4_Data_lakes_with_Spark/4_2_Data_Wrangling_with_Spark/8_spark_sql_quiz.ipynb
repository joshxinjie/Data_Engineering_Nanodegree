{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL Quiz\n",
    "\n",
    "This quiz uses the same dataset and questions from the Spark Data Frames Programming Quiz. For this quiz, however, use Spark SQL instead of Spark Data Frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# TODOS: \n",
    "# 1) import any other libraries you might need\n",
    "# 2) instantiate a Spark session \n",
    "# 3) read in the data set located at the path \"data/sparkify_log_small.json\"\n",
    "# 4) create a view to use with your SQL queries\n",
    "# 5) write code to answer the quiz questions\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark SQL Quiz\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "path = \"data/sparkify_log_small.json\"\n",
    "user_log = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temporary view to run sql queries\n",
    "user_log.createOrReplaceTempView(\"user_log_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Which page did user id \"\"(empty string) NOT visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| page|\n",
      "+-----+\n",
      "| Home|\n",
      "|About|\n",
      "|Login|\n",
      "| Help|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 1\n",
    "spark.sql('SELECT DISTINCT page FROM user_log_table WHERE userId = \"\"').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Reflect\n",
    "\n",
    "Why might you prefer to use SQL over data frames? Why might you prefer data frames over SQL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "How many female users do we have in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|count(DISTINCT userId)|\n",
      "+----------------------+\n",
      "|                   462|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 3\n",
    "spark.sql('SELECT COUNT(DISTINCT userId) FROM user_log_table WHERE gender=\"F\"').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "How many songs were played from the most played artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|  artist|numPlays|\n",
      "+--------+--------+\n",
      "|Coldplay|      83|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 4\n",
    "spark.sql('SELECT artist, COUNT(artist) AS numPlays \\\n",
    "FROM user_log_table \\\n",
    "GROUP BY artist \\\n",
    "ORDER BY numPlays DESC \\\n",
    "LIMIT 1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|  artist|numPlays|\n",
      "+--------+--------+\n",
      "|Coldplay|      83|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# alternative solution\n",
    "# get artist play count\n",
    "play_counts = spark.sql('SELECT artist, COUNT(artist) AS numPlays \\\n",
    "FROM user_log_table \\\n",
    "GROUP BY artist')\n",
    "\n",
    "# save the results in a new view\n",
    "play_counts.createOrReplaceTempView(\"artist_counts\")\n",
    "\n",
    "# use a self join to find where the max play equals the count value\n",
    "spark.sql('SELECT a2.artist, a2.numPlays \\\n",
    "FROM (SELECT MAX(numPlays) AS max_plays FROM artist_counts) as a1 \\\n",
    "JOIN artist_counts AS a2 \\\n",
    "ON a1.max_plays = a2.numPlays').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (challenge)\n",
    "\n",
    "How many songs do users listen to on average between visiting our home page? Please round your answer to the closest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write your code to answer question 5\n",
    "\n",
    "is_home = spark.sql('SELECT userId, page, ts, CASE WHEN page = \"Home\" THEN 1 ELSE 0 END AS is_home \\\n",
    "FROM user_log_table \\\n",
    "WHERE (page=\"NextSong\") or (page = \"Home\")')\n",
    "\n",
    "# keep the results in a new view\n",
    "is_home.createOrReplaceTempView(\"is_home_table\")\n",
    "\n",
    "# find the cumulative sum over the is_home column\n",
    "cumulative_sum = spark.sql('SELECT *, SUM(is_home) OVER \\\n",
    "(PARTITION BY userId ORDER BY ts DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS period \\\n",
    "FROM is_home_table')\n",
    "\n",
    "# keep the results in a view\n",
    "cumulative_sum.createOrReplaceTempView(\"period_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------+-------+------+\n",
      "|userId|    page|           ts|is_home|period|\n",
      "+------+--------+-------------+-------+------+\n",
      "|  1436|NextSong|1513783259284|      0|     0|\n",
      "|  1436|NextSong|1513782858284|      0|     0|\n",
      "|  2088|    Home|1513805972284|      1|     1|\n",
      "|  2088|NextSong|1513805859284|      0|     1|\n",
      "|  2088|NextSong|1513805494284|      0|     1|\n",
      "|  2088|NextSong|1513805065284|      0|     1|\n",
      "|  2088|NextSong|1513804786284|      0|     1|\n",
      "|  2088|NextSong|1513804555284|      0|     1|\n",
      "|  2088|NextSong|1513804196284|      0|     1|\n",
      "|  2088|NextSong|1513803967284|      0|     1|\n",
      "|  2088|NextSong|1513803820284|      0|     1|\n",
      "|  2088|NextSong|1513803651284|      0|     1|\n",
      "|  2088|NextSong|1513803413284|      0|     1|\n",
      "|  2088|NextSong|1513803254284|      0|     1|\n",
      "|  2088|NextSong|1513803057284|      0|     1|\n",
      "|  2088|NextSong|1513802824284|      0|     1|\n",
      "|  2162|NextSong|1513781246284|      0|     0|\n",
      "|  2162|NextSong|1513781065284|      0|     0|\n",
      "|  2162|NextSong|1513780860284|      0|     0|\n",
      "|  2162|NextSong|1513780569284|      0|     0|\n",
      "+------+--------+-------------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cumulative_sum.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg(count_results)|\n",
      "+------------------+\n",
      "| 6.898347107438017|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the average count for NextSong\n",
    "spark.sql('SELECT AVG(count_results) \\\n",
    "FROM (SELECT COUNT(*) AS count_results \\\n",
    "FROM period_table \\\n",
    "GROUP BY userId, period, page HAVING page = \"NextSong\") AS counts').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
